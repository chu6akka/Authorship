# Техническое предложение: ПО для судебной русскоязычной автороведческой экспертизы

## 1) Назначение системы

Система предназначена для **поддержки судебного эксперта-лингвиста** при исследовании письменной речи на русском языке (включая интернет-коммуникацию) и для автоматизации рутинных этапов:

- структурирование материалов дела;
- извлечение количественных и качественных признаков письменной речи;
- сопоставление спорного текста и образцов;
- генерация проекта экспертных формулировок (черновика выводов), подлежащего обязательной верификации экспертом.

> Важно: система не заменяет эксперта и не выносит «самостоятельный процессуальный вывод», а формирует аргументированный аналитический отчет и шаблоны формулировок.

---

## 2) Методологическая рамка (как операционализируется)

Ниже — как программно поддержать подходы, типичные для судебного речеведения и автороведения (в логике работ Е.И. Галяшиной, С.М. Вула и сопряженной литературы):

1. **Уровневый анализ признаков**:
   - графико-орфографический;
   - лексико-фразеологический;
   - морфологический;
   - синтаксический;
   - текстово-дискурсивный;
   - коммуникативно-прагматический.

2. **Разделение признаков**:
   - общие (жанр, стиль, регистр, тематика);
   - частные/идиолектные (устойчивые индивидуальные предпочтения).

3. **Сопоставительный принцип**:
   - анализ «исследуемый текст ↔ корпус образцов»;
   - фиксация совпадений, различий, устойчивости признаков;
   - оценка диагностической значимости каждого признака.

4. **Прозрачность доказательственной базы**:
   - каждая метрика сопровождается фрагментами-иллюстрациями;
   - сохраняется трассировка: от исходного текста к признаку и к формулировке вывода.

---

## 3) Предлагаемый функционал (MVP → расширенная версия)

## 3.1. Управление делом (Case Management)

- карточка дела: номер, основания, вопросы эксперту, стороны;
- загрузка материалов: DOCX/PDF/TXT/скриншоты/логи чатов;
- разметка ролей: «исследуемый текст», «свободные образцы», «условно-свободные», «экспериментальные»;
- контроль метаданных: дата, канал коммуникации, язык/смешение языков, объем.

## 3.2. Препроцессинг и нормализация

- OCR (при необходимости);
- очистка артефактов копирования;
- сегментация на абзацы/реплики/предложения;
- токенизация;
- лемматизация и морфоразбор (pymorphy3/2);
- NER, syntax/dependency, sentence parsing (Natasha);
- выделение эмотиконов, emoji, хэштегов, ссылок, @упоминаний, латиницы/кириллицы.

## 3.3. Модуль признаков письменной речи

### A) Графика, орфография, пунктуация
- частотность пунктуационных моделей (многоточия, повтор «!!!», «??»);
- орфографические типы отклонений;
- вариативность написания (ё/е, слитно-раздельно, авторские написания);
- капс/нижний регистр, повторы букв ("круууто").

### B) Лексика и фразеология
- частотные леммы, n-граммы, keyness;
- разговорная/сниженная/жаргонная/вульгарная лексика;
- тематические доминанты и их устойчивость;
- клише, речевые формулы, дискурсивные маркеры.

### C) Морфология
- распределение частей речи;
- предпочтения по граммемам (время, вид, лицо, наклонение);
- доля местоимений, служебных слов, частиц;
- морфологическая «сигнатура» текста.

### D) Синтаксис
- средняя длина предложения и клауз;
- глубина синтаксического дерева;
- типы конструкций (простые/сложные, бессоюзие, парцелляция);
- модели порядка слов.

### E) Текст, стиль, прагматика
- связность (когезия, референциальные цепочки);
- композиционные паттерны;
- регистр и функционально-стилевая маркированность;
- коммуникативная направленность (информирование/воздействие/контакт).

### F) Признаки интернет-коммуникации
- смешение кодов (code-switching, RU+EN и др.);
- транслитерация;
- сокращения, сетевой сленг;
- эмотиконы/emoji и авторские паттерны их использования.

## 3.4. Сравнение «образец ↔ исследуемый текст»

Обязательный функционал, который вы запросили:

1. **Полностью идентичные формулировки**
   - поиск совпадений по exact match;
   - поиск совпадающих n-грамм заданной длины;
   - подсветка совпавших фрагментов в обоих текстах.

2. **Синонимизм**
   - сопоставление лемм с учетом словарей синонимов;
   - контекстная проверка допустимости замены (чтобы отсечь ложные срабатывания);
   - отчет: «фраза A ↔ фраза B, тип синонимической замены».

3. **Перефраз (парафраз)**
   - семантическое сопоставление предложений (sentence embeddings);
   - выявление структурно разных, но смыслово близких фрагментов;
   - классификация перефраза: лексический / синтаксический / смешанный.

4. **Транслитерация и межалфавитные соответствия**
   - нормализация латиница↔кириллица (например, "privet" ↔ "привет");
   - учет смешанных токенов ("coherence skill", "done", "kul");
   - фиксация повторяющихся индивидуальных транслит-привычек.

5. **Иные частные признаки авторства**
   - устойчивые опечатки;
   - характерные вводные слова/частицы;
   - паттерны пунктуации;
   - шаблоны обращения к собеседнику;
   - специфические эмотиконы/emoji-последовательности.

## 3.5. Автоматизация формулировок выводов

### Шаблонизатор экспертного текста

- библиотека формулировок: описательная, исследовательская, синтезирующая части;
- параметры шаблонов:
  - уровень уверенности,
  - достаточность сравнительного материала,
  - перечень ключевых совпадений/различий,
  - ограничения исследования.

### Что автоматизируется
- черновые формулировки вида:
  - «Установлены следующие устойчивые совпадающие признаки…»
  - «Выявленные различия могут объясняться…»
  - «С учетом совокупности признаков…»
- автоматическое включение таблиц и цитатных иллюстраций;
- авто-ссылки на фрагменты текста (traceability).

### Что не автоматизируется
- окончательный процессуальный вывод от имени эксперта;
- правовая квалификация;
- оценка доказательственного значения вне лингвистической компетенции.

## 3.6. Отчетность

- экспорт: DOCX/PDF + машиночитаемый JSON;
- приложения:
  - таблица признаков,
  - карта совпадений,
  - статистические графики,
  - список источников/словарей/версий моделей;
- журнал воспроизводимости:
  - версии библиотек,
  - дата обработки,
  - параметры пайплайна.

---

## 4) Архитектура (Natasha + pymorphy + ML)

## 4.1. Технологический стек
- **Backend**: Python (FastAPI), Celery/RQ для фоновых задач;
- **NLP-база**:
  - Natasha (сегментация, NER, синтаксис);
  - pymorphy (лемматизация, морфология);
  - razdel/rutokenizer;
  - ruWordNet/синонимические словари;
  - sentence-transformers (ru-модели) для парафраза;
- **Хранилище**:
  - PostgreSQL (данные дела, признаки);
  - MinIO/S3 (документы);
  - Elasticsearch/OpenSearch (поиск по корпусу);
- **Frontend**: React/Vue (подсветка фрагментов и экспертный редактор).

## 4.2. Внутренние сервисы
- `ingestion-service` (импорт и нормализация);
- `linguistic-feature-service` (извлечение признаков);
- `comparison-service` (совпадения/синонимы/перефраз/транслит);
- `report-service` (генерация проекта заключения);
- `audit-service` (логирование, воспроизводимость, цепочка хранения).

---

## 5) Решаемые задачи автоматизации

1. Сокращение времени первичного анализа текста.
2. Стандартизация выделения признаков между экспертами.
3. Повышение полноты поиска совпадений и скрытых соответствий.
4. Прозрачная, проверяемая аргументация для суда.
5. Уменьшение рутинной нагрузки при подготовке текста заключения.
6. Повышение воспроизводимости при повторных/комиссионных экспертизах.

---

## 6) Пример структуры выводной части (черновик)

1. Исходные данные и объем материала.
2. Методика и примененные инструменты.
3. Установленные общие признаки письменной речи.
4. Установленные частные (идиолектные) признаки.
5. Результаты сравнительного анализа:
   - идентичные формулировки,
   - синонимические соответствия,
   - парафраз,
   - транслитерация,
   - иные устойчивые признаки.
6. Оценка совокупности признаков и их диагностической значимости.
7. Ограничения исследования.
8. Проект ответа на вопросы, поставленные перед экспертом.

---

## 7) Легкий MVP (без IT-бэкграунда) + поэтапное расширение

Ниже — версия MVP, рассчитанная на пользователя-эксперта, который не должен настраивать модели, базы данных и пайплайны вручную.

### 7.1. Принципы «легкого» MVP

- **Один экран — один сценарий**: «загрузил → сравнил → получил отчет»;
- **без ручной настройки NLP**: предустановленные параметры и методические профили;
- **минимум технических терминов в интерфейсе**: вместо «лемматизация» — «нормализация слов»;
- **обязательные подсказки**: что означает каждый показатель и как его интерпретировать в экспертном тексте;
- **без DevOps для старта**: локальный инсталлятор/desktop-вариант или веб-версия с готовым окружением.

### 7.2. Функции MVP v1 (аналитическое ядро)

1. **Мастер загрузки материалов**
   - 2 типа документов: «исследуемый текст» и «образцы для сравнения»;
   - автопроверка формата и читаемости;
   - автоподсчет объема (слов, словоформ, абзацев, предложений).

2. **Быстрый сравнительный анализ (кнопка "Сравнить")**
   - полные совпадения формулировок;
   - совпадения n-грамм;
   - базовый синонимизм (по словарю);
   - базовый перефраз (по порогу семантической близости);
   - транслитерация и смешение кириллица/латиница;
   - маркеры интернет-коммуникации (эмотиконы, повторы, сленг).

3. **Визуальный режим "Покажи, где именно"**
   - подсветка найденных фрагментов цветами по типам признаков;
   - синхронная навигация: фрагмент в исследуемом тексте ↔ фрагмент в образце;
   - фильтр «показывать только сильные совпадения».

4. **Полуавтоматический проект выводов**
   - готовые формулировки с заполнением по данным анализа;
   - блок «факты и иллюстрации» под каждой формулировкой;
   - пометка «требует экспертной верификации» перед экспортом.

5. **Экспорт без доработки IT-специалистом**
   - DOCX/PDF-отчет;
   - приложение с таблицей совпадений;
   - краткий «паспорт исследования» (дата, версия алгоритмов, входные файлы).

### 7.3. Ограничения MVP v1 (честно для пользователя)

- без сложной кастомизации моделей;
- ограниченная глубина синтаксико-дискурсивного анализа;
- вероятностный модуль перефраза работает как вспомогательный индикатор;
- итоговый процессуальный вывод подписывает только эксперт.

### 7.4. Пошаговое наращивание функционала

**Этап A (MVP, 6–10 недель)**
- мастер загрузки + базовая аналитика + подсветка + экспорт;
- преднастроенные словари и пороги;
- 2–3 шаблона выводов под типовые задачи.

**Этап B (расширение, +8–12 недель)**
- более точная синонимия/перефраз (контекстная проверка);
- расширенные морфо-синтаксические профили;
- сравнение нескольких наборов образцов и пакетный режим дел.

**Этап C (профессиональная версия)**
- тонкая настройка методических профилей под учреждение;
- валидация на внутреннем корпусе и калибровка порогов;
- API-интеграции с электронным документооборотом.

---

## 8) Ограничения и валидация

- минимальный объем текста для надежных статистических выводов должен быть задан регламентом;
- результаты чувствительны к жанру/каналу/времени создания текста;
- нужна периодическая экспертная ревизия словарей и моделей;
- обязательна протоколируемая валидация на размеченном корпусе (precision/recall/F1 по типам признаков).

---

## 9) Что можно сделать следующим шагом

1. Сформировать **матрицу признаков** (обязательные/дополнительные) под ваш процессуальный стандарт.
2. Подготовить **ТЗ в формате ГОСТ/внутриведомственного стандарта**.
3. Собрать **демо-корпус** и провести пилот с 20–30 делами.
4. Настроить шаблоны формулировок под вашу организацию.
